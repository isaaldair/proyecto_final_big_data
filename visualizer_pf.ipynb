{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc1f6f5-0312-449a-87e1-1a59bf5256a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Monitor Kafka ‚Äî seguimiento de eventos y latencia\n",
      "\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n",
      "‚ö†Ô∏è A√∫n no existe el archivo CSV. Esperando datos...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "\n",
    "# =======================================\n",
    "# 1. CONFIGURACI√ìN DEL MONITOR\n",
    "# =======================================\n",
    "\n",
    "# üö® ESTA RUTA DEBE COINCIDIR con la ruta donde el Consumer guarda los resultados.\n",
    "AGGREGATED_OUTPUT_PATH = \"output_realtime_analysis/aggregated_data\"\n",
    "# Tiempo de espera entre cada chequeo de archivos nuevos (en segundos)\n",
    "REFRESH_INTERVAL = 5 # <--- CAMBIADO A 5 SEGUNDOS\n",
    "# Ventana de tiempo para monitorear archivos recientes (en segundos)\n",
    "RECENT_WINDOW_SECONDS = 60 \n",
    "\n",
    "# =======================================\n",
    "# 2. ESTRUCTURAS DE DATOS Y PLOTTER\n",
    "# =======================================\n",
    "\n",
    "plt.ion() # Habilitar modo interactivo para actualizaci√≥n din√°mica\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Diccionario persistente en memoria para acumular las ventas totales por zona\n",
    "sales_by_zone = {} \n",
    "# Conjunto para rastrear qu√© archivos CSV (part-000...) ya fueron procesados\n",
    "processed_files = set() \n",
    "\n",
    "def update_realtime_plot():\n",
    "    \"\"\"Genera y refresca el gr√°fico de barras din√°mico (Top 10 Ventas por Zona).\"\"\"\n",
    "    \n",
    "    if not sales_by_zone:\n",
    "        ax.clear()\n",
    "        ax.text(0.5, 0.5, \"Esperando datos del Consumer...\", \n",
    "                horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "        ax.set_title(f\"Visualizador Activo - {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        plt.draw()\n",
    "        plt.pause(0.001)\n",
    "        return\n",
    "        \n",
    "    # An√°lisis: Top 10 Zonas (Requerimiento 4: Top Elementos)\n",
    "    sorted_sales = sorted(sales_by_zone.items(), key=lambda item: item[1], reverse=True)[:10]\n",
    "    zones = [item[0] for item in sorted_sales]\n",
    "    sales = [item[1] for item in sorted_sales]\n",
    "    \n",
    "    # 2. Actualizar el gr√°fico\n",
    "    ax.clear() \n",
    "    \n",
    "    y_pos = np.arange(len(zones))\n",
    "    ax.barh(y_pos, sales, color='#00A388') \n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(zones, fontsize=10)\n",
    "    \n",
    "    ax.set_title(f'Ventas Acumuladas de Uber por Zona (Top 10) - {datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "    ax.set_xlabel('Total Uber Sales Acumuladas ($)')\n",
    "    ax.set_ylabel('Zona de Recogida')\n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.draw()\n",
    "    plt.pause(0.001)\n",
    "\n",
    "def load_new_data():\n",
    "    \"\"\"Busca y carga nuevos archivos CSV generados por Spark, actualizando el an√°lisis.\"\"\"\n",
    "    global processed_files\n",
    "    \n",
    "    all_files = glob.glob(f\"{AGGREGATED_OUTPUT_PATH}/part-*.csv\")\n",
    "    new_files = [f for f in all_files if f not in processed_files]\n",
    "    \n",
    "    new_data_count = 0\n",
    "    \n",
    "    for file_path in new_files:\n",
    "        try:\n",
    "            # Usar Pandas para cargar el nuevo archivo de lote\n",
    "            df_new = pd.read_csv(file_path)\n",
    "            \n",
    "            for index, row in df_new.iterrows():\n",
    "                zone = row['pickup_zone']\n",
    "                sales = row['total_sales_zone'] if not pd.isna(row['total_sales_zone']) else 0\n",
    "                \n",
    "                sales_by_zone[zone] = sales_by_zone.get(zone, 0) + sales\n",
    "                new_data_count += 1\n",
    "            \n",
    "            processed_files.add(file_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Esto maneja el caso donde Spark a√∫n no ha terminado de escribir el archivo\n",
    "            pass # Ignoramos el error para intentarlo en el pr√≥ximo ciclo\n",
    "\n",
    "    return new_data_count\n",
    "\n",
    "def monitor_recent_files():\n",
    "    \"\"\"Busca archivos creados en el AGGREGATED_OUTPUT_PATH en los √∫ltimos 60 segundos.\"\"\"\n",
    "    \n",
    "    time_limit = datetime.now() - timedelta(seconds=RECENT_WINDOW_SECONDS)\n",
    "    recent_files = []\n",
    "    \n",
    "    # Buscar todos los archivos de Spark, incluyendo .csv y _SUCCESS\n",
    "    all_items = glob.glob(f\"{AGGREGATED_OUTPUT_PATH}/*\")\n",
    "    \n",
    "    for item in all_items:\n",
    "        # Obtener el tiempo de modificaci√≥n del archivo\n",
    "        mod_time = datetime.fromtimestamp(os.path.getmtime(item))\n",
    "        \n",
    "        if mod_time >= time_limit and os.path.isfile(item):\n",
    "            # Formato de la hora de modificaci√≥n\n",
    "            time_str = mod_time.strftime(\"%H:%M:%S\")\n",
    "            recent_files.append(f\"[{time_str}] {os.path.basename(item)}\")\n",
    "            \n",
    "    return recent_files\n",
    "\n",
    "# =======================================\n",
    "# 3. BUCLE PRINCIPAL DE MONITORIZACI√ìN\n",
    "# =======================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    if not os.path.isdir(AGGREGATED_OUTPUT_PATH):\n",
    "        print(f\"ERROR: No se encontr√≥ el directorio de salida: '{AGGREGATED_OUTPUT_PATH}'.\")\n",
    "        print(\"Aseg√∫rate de ejecutar el Kafka_Processor.py primero.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(\"\\n--- VISUALIZADOR DE DATOS EN TIEMPO REAL INICIADO ---\")\n",
    "    print(f\"Monitoreando la carpeta: {AGGREGATED_OUTPUT_PATH} cada {REFRESH_INTERVAL} segundos.\")\n",
    "    \n",
    "    # Inicializa la ventana de espera\n",
    "    update_realtime_plot() \n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # 1. Cargar nuevos datos y actualizar an√°lisis\n",
    "            num_updates = load_new_data()\n",
    "            \n",
    "            if num_updates > 0:\n",
    "                print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] --- NUEVO LOTE PROCESADO ---\")\n",
    "                print(f\"-> Procesados {num_updates} nuevos registros.\")\n",
    "                update_realtime_plot()\n",
    "            \n",
    "            # 2. Monitoreo de actividad de archivos (√öltimos 60s)\n",
    "            recent_activity = monitor_recent_files()\n",
    "            \n",
    "            print(f\"\\n--- Actividad de Archivos (√öltimos {RECENT_WINDOW_SECONDS}s) ---\")\n",
    "            if recent_activity:\n",
    "                for f in recent_activity:\n",
    "                    print(f\" [NUEVO] {f}\")\n",
    "            else:\n",
    "                print(\" No se detect√≥ actividad de escritura reciente.\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            time.sleep(REFRESH_INTERVAL)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nVisualizador detenido por el usuario.\")\n",
    "        plt.close(fig)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fatal del visualizador: {e}\")\n",
    "        plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
